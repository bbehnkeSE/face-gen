{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from   torch import optim\n",
    "import torchvision.datasets   as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils      as vutils\n",
    "from   torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot      as plt\n",
    "import numpy                  as np\n",
    "\n",
    "from   model import Generator\n",
    "from   model import Critic\n",
    "from   tqdm  import tqdm\n",
    "from   math  import log2\n",
    "\n",
    "from   IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR        = \"../data/flikr_hq/\"\n",
    "GEN_CHECKPOINT  = \"gen.pth\"\n",
    "CRIT_CHECKPOINT = \"crit.pth\"\n",
    "DEVICE          = \"cuda\"\n",
    "SAVE_MODEL      = True\n",
    "LOAD_MODEL      = False\n",
    "START_IMG_SIZE  = 4\n",
    "LEARNING_RATE   = 1e-3\n",
    "BATCH_SIZES     = [512, 512, 256, 128, 64, 32]\n",
    "IMG_CHANNELS    = 3\n",
    "Z_DIM           = 512\n",
    "IN_CHANNELS     = 512\n",
    "LAMBDA_GP       = 10\n",
    "PROG_EPOCHS     = [24] * len(BATCH_SIZES)\n",
    "NUM_WORKERS     = 24\n",
    "\n",
    "torch.backends.cudnn.benchmarks = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real, fake, alpha, train_step, device):\n",
    "    batch_size, img_channels, h, w = real.shape\n",
    "    beta = torch.rand((batch_size, 1, 1, 1)).repeat(1, img_channels, h, w).to(device)\n",
    "    mixed_imgs = real * beta + fake.detach() * (1 - beta)\n",
    "    mixed_imgs.requires_grad_(True)\n",
    "    mixed_scores = critic(mixed_imgs, alpha, train_step)\n",
    "\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=mixed_imgs,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    \n",
    "    return penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optim, filename=\"progan_ckpnt.pth\"):\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optim.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(filename, model, optim, lr):\n",
    "    checkpoint = torch.load(filename, map_location=\"cuda\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optim.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    for group in optim.param_groups:\n",
    "        group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(img_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.Normalize(\n",
    "            [0.5 for _ in range(IMG_CHANNELS)],\n",
    "            [0.5 for _ in range(IMG_CHANNELS)]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(root=DATA_DIR, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZES[int(log2(img_size/4))], shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    return loader, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(Z_DIM, IN_CHANNELS, IMG_CHANNELS).to(DEVICE)\n",
    "crit = Critic(IN_CHANNELS, IMG_CHANNELS).to(DEVICE)\n",
    "\n",
    "gen_optim = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.99))\n",
    "crit_optim = optim.Adam(crit.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.99))\n",
    "\n",
    "gen_scalar = torch.cuda.amp.GradScaler()\n",
    "crit_scalar = torch.cuda.amp.GradScaler()\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    print(\"### Loading checkpoints ###\")\n",
    "    load_checkpoint(GEN_CHECKPOINT, gen, gen_optim, LEARNING_RATE)\n",
    "    load_checkpoint(CRIT_CHECKPOINT, crit, crit_optim, LEARNING_RATE)\n",
    "\n",
    "gen.train()\n",
    "crit.train()\n",
    "\n",
    "step = int(log2(START_IMG_SIZE / 4))\n",
    "\n",
    "for epochs in PROG_EPOCHS[step:]:\n",
    "    alpha = 0\n",
    "    loader, dataset = get_loader(4 * 2 ** step)\n",
    "    clear_output()\n",
    "    print(f\"\\nImage size: {4 * 2 ** step}\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}]\")\n",
    "\n",
    "        loop = tqdm(loader, leave=True)\n",
    "        for batch_idx, (real, _) in enumerate(loop):\n",
    "            real = real.to(DEVICE)\n",
    "            cur_batch_size = real.shape[0]\n",
    "\n",
    "            # Train critic\n",
    "            noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(DEVICE)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                fake = gen(noise, alpha, step)\n",
    "                real_pred = crit(real, alpha, step)\n",
    "                fake_pred = crit(fake.detach(), alpha, step)\n",
    "                gp = gradient_penalty(crit, real, fake, alpha, step, DEVICE)\n",
    "                crit_loss = -(torch.mean(real_pred) - torch.mean(fake_pred)) + LAMBDA_GP * gp + (0.001 * torch.mean(real_pred ** 2))\n",
    "\n",
    "            crit_optim.zero_grad()\n",
    "            crit_scalar.scale(crit_loss).backward()\n",
    "            crit_scalar.step(crit_optim)\n",
    "            crit_scalar.update()\n",
    "\n",
    "            # Train generator\n",
    "            with torch.cuda.amp.autocast():\n",
    "                gen_fake = crit(fake, alpha, step)\n",
    "                gen_loss = -torch.mean(gen_fake)\n",
    "\n",
    "            gen_optim.zero_grad()\n",
    "            gen_scalar.scale(gen_loss).backward()\n",
    "            gen_scalar.step(gen_optim)\n",
    "            gen_scalar.update()\n",
    "\n",
    "            if alpha < 1:\n",
    "                alpha += cur_batch_size / ((PROG_EPOCHS[step] * 0.5) * len(dataset))\n",
    "                alpha = min(alpha, 1)\n",
    "\n",
    "            loop.set_postfix(\n",
    "                gp=gp.item(), \n",
    "                crit_loss=crit_loss.item(), \n",
    "                gen_loss=gen_loss.item(),\n",
    "                alpha=alpha\n",
    "            )\n",
    "\n",
    "            \n",
    "        if SAVE_MODEL:\n",
    "            print(\"### Saving checkpoints ###\")\n",
    "            save_checkpoint(gen, gen_optim, filename=GEN_CHECKPOINT)\n",
    "            save_checkpoint(crit, crit_optim, filename=CRIT_CHECKPOINT)\n",
    "\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Sample Generation\")\n",
    "        plt.imshow(np.transpose(vutils.make_grid(fake.to(DEVICE)[:16], padding=2, normalize=True).cpu(), (1, 2, 0)))\n",
    "        plt.show()\n",
    "\n",
    "    step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
