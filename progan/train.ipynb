{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from   torch import nn\n",
    "from   math  import log2\n",
    "from   torch import optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from   torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot      as plt\n",
    "import matplotlib.animation   as animation\n",
    "import numpy as np\n",
    "\n",
    "from model import Generator\n",
    "from model import Critic\n",
    "from tqdm  import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/flikr_hq/\"\n",
    "START_IMG_SIZE = 4\n",
    "GEN_CHECKPOINT = \"gen.pth\"\n",
    "CRIT_CHECKPOINT = \"crit.pth\"\n",
    "DEVICE = \"cuda\"\n",
    "SAVE_MODEL = True\n",
    "LOAD_MODEL = False\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = 1024\n",
    "IMG_CHANNELS = 3\n",
    "Z_DIM = 512\n",
    "IN_CHANNELS = 512\n",
    "LAMBDA_GP = 10\n",
    "NUM_STEPS = int(log2(IMG_SIZE / 4)) + 1\n",
    "PROG_EPOCHS = [30] * 9\n",
    "FIXED_NOISE = torch.randn(8, Z_DIM, 1, 1).to(DEVICE)\n",
    "NUM_WORKERS = 32\n",
    "DISPLAY_STEP = 500\n",
    "\n",
    "torch.backends.cudnn.benchmarks = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real, fake, alpha, train_step, device):\n",
    "    batch_size, img_channels, h, w = real.shape\n",
    "    beta = torch.rand((batch_size, 1, 1, 1)).repeat(1, img_channels, h, w).to(device)\n",
    "    mixed_imgs = real * beta + fake.detach() * (1 - beta)\n",
    "    mixed_imgs.requires_grad_(True)\n",
    "    mixed_scores = critic(mixed_imgs, alpha, train_step)\n",
    "\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=mixed_imgs,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    \n",
    "    return penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optim, filename=\"progan_ckpnt.pth\"):\n",
    "    print(\"### Saving checkpoint ###\")\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optim.state_dict()\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(filename, model, optim, lr):\n",
    "    print(\"### Loading checkpoint ###\")\n",
    "    checkpoint = torch.load(filename, map_location=\"cuda\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optim.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    for group in optim.param_groups:\n",
    "        group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(img_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(img_size, img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.5 for _ in range(IMG_CHANNELS)],\n",
    "            [0.5 for _ in range(IMG_CHANNELS)]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(root=DATA_DIR, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    return loader, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 4\n",
      "Epoch [1/30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 448/1094 [00:46<01:07,  9.60it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# alpha = train(gen, crit, loader, dataset, step, alpha, gen_optim, crit_optim, gen_scalar, crit_scalar, epoch)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m loop \u001b[38;5;241m=\u001b[39m tqdm(loader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (real, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loop):\n\u001b[1;32m     32\u001b[0m     real \u001b[38;5;241m=\u001b[39m real\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     33\u001b[0m     cur_batch_size \u001b[38;5;241m=\u001b[39m real\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/gans/venv/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/gans/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/gans/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/gans/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1285\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1285\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1287\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/gans/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gen = Generator(Z_DIM, IN_CHANNELS, IMG_CHANNELS).to(DEVICE)\n",
    "crit = Critic(IN_CHANNELS, IMG_CHANNELS).to(DEVICE)\n",
    "\n",
    "gen_optim = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.99))\n",
    "crit_optim = optim.Adam(crit.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.99))\n",
    "\n",
    "gen_scalar = torch.cuda.amp.GradScaler()\n",
    "crit_scalar = torch.cuda.amp.GradScaler()\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    load_checkpoint(GEN_CHECKPOINT, gen, gen_optim, LEARNING_RATE)\n",
    "    load_checkpoint(CRIT_CHECKPOINT, crit, crit_optim, LEARNING_RATE)\n",
    "\n",
    "gen.train()\n",
    "crit.train()\n",
    "\n",
    "step = int(log2(START_IMG_SIZE / 4))\n",
    "\n",
    "img_list = []\n",
    "\n",
    "for epochs in PROG_EPOCHS[step:]:\n",
    "    alpha = 0\n",
    "    loader, dataset = get_loader(4 * 2 ** step)\n",
    "    print(f\"Image size: {4 * 2 ** step}\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}]\")\n",
    "\n",
    "        # alpha = train(gen, crit, loader, dataset, step, alpha, gen_optim, crit_optim, gen_scalar, crit_scalar, epoch)\n",
    "        loop = tqdm(loader, leave=True)\n",
    "        for batch_idx, (real, _) in enumerate(loop):\n",
    "            real = real.to(DEVICE)\n",
    "            cur_batch_size = real.shape[0]\n",
    "\n",
    "            # Train critic\n",
    "            noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(DEVICE)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                fake = gen(noise, alpha, step)\n",
    "                real_pred = crit(real, alpha, step)\n",
    "                fake_pred = crit(fake.detach(), alpha, step)\n",
    "                gp = gradient_penalty(crit, real, fake, alpha, step, DEVICE)\n",
    "                crit_loss = -(torch.mean(real_pred) - torch.mean(fake_pred)) + LAMBDA_GP * gp + (0.001 * torch.mean(real_pred ** 2))\n",
    "\n",
    "            crit_optim.zero_grad()\n",
    "            crit_scalar.scale(crit_loss).backward()\n",
    "            crit_scalar.step(crit_optim)\n",
    "            crit_scalar.update()\n",
    "\n",
    "            # Train generator\n",
    "            with torch.cuda.amp.autocast():\n",
    "                gen_fake = crit(fake, alpha, step)\n",
    "                gen_loss = -torch.mean(gen_fake)\n",
    "\n",
    "            gen_optim.zero_grad()\n",
    "            gen_scalar.scale(gen_loss).backward()\n",
    "            gen_scalar.step(gen_optim)\n",
    "            gen_scalar.update()\n",
    "\n",
    "            alpha += cur_batch_size / (PROG_EPOCHS[step] * 0.5) + len(dataset)\n",
    "            alpha = min(alpha, 1)\n",
    "\n",
    "            if batch_idx % DISPLAY_STEP == 0 and batch_idx > 0:\n",
    "                with torch.no_grad():\n",
    "                    fake = gen(FIXED_NOISE, alpha, step).detach().cpu()\n",
    "                img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        if SAVE_MODEL:\n",
    "            save_checkpoint(gen, gen_optim, filename=GEN_CHECKPOINT)\n",
    "            save_checkpoint(crit, crit_optim, filename=CRIT_CHECKPOINT)\n",
    "\n",
    "    step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
